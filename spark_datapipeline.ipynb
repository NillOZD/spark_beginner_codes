{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+GjjryqpgRN6g3l3U8aPF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0TB7MvdqKn4",
        "outputId": "8f31296f-df76-4d73-b8a2-df7905a3448e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 48.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=ac9b6504f020c70983e4a0332caf11e93e47cc43365ad670e68f4fc77a6036e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import HashingTF, Tokenizer, IDF\n",
        "from pyspark.ml.classification import  LogisticRegression\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  spark = SparkSession \\\n",
        "          .builder \\\n",
        "          .appName(\"pipeline_ex\") \\\n",
        "          .getOrCreate()\n",
        "\n",
        "new_data = spark.createDataFrame([\n",
        "    (0, \"3 5 6 ayse fatma nil\", 1.0),\n",
        "    (1, \"nursel zuleyha gamze 8 9\", 0.0 ),\n",
        "    (2, \"kutuphane spark nil 5\", 1.0),\n",
        "    (3, \"kitaplar 56 bilgisayar\", 0.0),\n",
        "    (4, \"nil cay mentor 9\", 1.0),\n",
        "    (5, \"2 agaclar yildiz\", 0.0)\n",
        "], [\"id\", \"text\", \"label\"])\n",
        "\n",
        "tokenizer = Tokenizer(inputCol= \"text\", outputCol=\"words\")\n",
        "hashing_tf = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
        "idf = IDF(inputCol=hashing_tf.getOutputCol(), outputCol=\"features\")\n",
        "log_reg = LogisticRegression(maxIter= 10, regParam= 0.001)\n",
        "pipeline = Pipeline(stages = [tokenizer, hashing_tf, log_reg])\n",
        "\n",
        "model = pipeline.fit(new_data)\n",
        "\n",
        "test_data = spark.createDataFrame([\n",
        "    (6, \"kalem 4 su apache\"),\n",
        "    (7, \"ai text nil\"),\n",
        "    (8, \"kurs cassandra university\"),\n",
        "    (9, \"9 8 nil 7\")\n",
        "], [\"id\", \"text\"])\n",
        "\n",
        "prediction = model.transform(test_data)\n",
        "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
        "for r in selected.collect():\n",
        "    row_id, text, probability, prediction = r\n",
        "    print(\"{}, {} prob= {}, pred={} \".format(row_id, text, probability, prediction))\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWCqzS9EqR3t",
        "outputId": "ab1d6b29-bfd6-470a-f6fc-e6de8722622f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6, kalem 4 su apache prob= [0.7869286716251876,0.21307132837481235], pred=0.0 \n",
            "7, ai text nil prob= [0.2035313652070624,0.7964686347929376], pred=1.0 \n",
            "8, kurs cassandra university prob= [0.7869286716251876,0.21307132837481235], pred=0.0 \n",
            "9, 9 8 nil 7 prob= [0.4028901338684307,0.5971098661315692], pred=1.0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMATIMf4qn70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}